{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Welcome to our Project 2 Notebook by Team Pandamonium - Luna Amador, Joshua Varughese and Ellen Wang\n",
    "\n",
    "This project aims to use socio-economic factors and other identified explanatory variables to predict the proportion of car sales taken up by different car size categories, including small, midsize and large categories. This will be achieved by developing 3 linear regression models and will allow car manufacturers to predict what size cars they should focus on developing based on the factors chosen below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from requests import get\n",
    "from functools import reduce\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section we scrape the GoodCarBadCar website to produce tables of models and monthly car sales from which we can form our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#these lists allow the loop below to accommodate the differences between websites for each year of carsales\n",
    "years = [2019, 2020, 2021]\n",
    "ranges = [594, 1, 580]\n",
    "\n",
    "#a list to store the scraped web data for car sales of each year\n",
    "carsaleslist = []\n",
    "\n",
    "for index, year in enumerate(years):\n",
    "    response = get('https://www.goodcarbadcar.net/{year}-canada-vehicle-sales-figures-by-model/' .format(year = year))\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table_rows = html_soup.find_all('tr')[ranges[index]:-1] #excludes the sum row\n",
    "\n",
    "    #lists to store the important data scraped from each webpage\n",
    "    model_names = []\n",
    "    january = []\n",
    "    february = []\n",
    "    march = []\n",
    "    april = []\n",
    "    may = []\n",
    "    june = []\n",
    "    july = []\n",
    "    august = []\n",
    "    september = []\n",
    "    october = []\n",
    "    november = []\n",
    "    december = []\n",
    "\n",
    "    # iterate through each row in the table\n",
    "    for row in table_rows:\n",
    "        # use certain tags positions and/or subtags, then extract the text, and use .strip() to remove leading whitespace, and then add them to the corresponding to list\n",
    "        model_name = row.find_all('td')[0].text.strip()\n",
    "        model_names.append(model_name)\n",
    "\n",
    "        jan_sum = row.find_all('td')[1].text.strip()\n",
    "        january.append(int(jan_sum.replace(',','')))\n",
    "\n",
    "        feb_sum = row.find_all('td')[2].text.strip()\n",
    "        february.append(int(feb_sum.replace(',','')))\n",
    "\n",
    "        mar_sum = row.find_all('td')[3].text.strip()\n",
    "        march.append(int(mar_sum.replace(',','')))\n",
    "\n",
    "        apr_sum = row.find_all('td')[4].text.strip()\n",
    "        april.append(int(apr_sum.replace(',','')))\n",
    "\n",
    "        may_sum = row.find_all('td')[5].text.strip()\n",
    "        may.append(int(may_sum.replace(',','')))\n",
    "\n",
    "        jun_sum = row.find_all('td')[6].text.strip()\n",
    "        june.append(int(jun_sum.replace(',','')))\n",
    "\n",
    "        jul_sum = row.find_all('td')[7].text.strip()\n",
    "        july.append(int(jul_sum.replace(',','')))\n",
    "\n",
    "        aug_sum = row.find_all('td')[8].text.strip()\n",
    "        august.append(int(aug_sum.replace(',','')))\n",
    "\n",
    "        sep_sum = row.find_all('td')[9].text.strip()\n",
    "        september.append(int(sep_sum.replace(',','')))\n",
    "\n",
    "        oct_sum = row.find_all('td')[10].text.strip()\n",
    "        october.append(int(oct_sum.replace(',','')))\n",
    "\n",
    "        nov_sum = row.find_all('td')[11].text.strip()\n",
    "        november.append(int(nov_sum.replace(',','')))\n",
    "\n",
    "        dec_sum = row.find_all('td')[12].text.strip()\n",
    "        december.append(int(dec_sum.replace(',','')))\n",
    "\n",
    "    #create a dataframe containing columns corresponding to the lists generated above\n",
    "    carsaleslist.append(pd.DataFrame({'make_and_model': model_names, '{year}-01-01'.format(year = year): january,\n",
    "                              '{year}-02-01'.format(year = year): february, '{year}-03-01'.format(year = year): march,'{year}-04-01'.format(year = year): april,\n",
    "                              '{year}-05-01'.format(year = year):may, '{year}-06-01'.format(year = year):june, '{year}-07-01'.format(year = year):july,'{year}-08-01'.format(year = year):august,\n",
    "                              '{year}-09-01'.format(year = year): september, '{year}-10-01'.format(year = year): october,\n",
    "                              '{year}-11-01'.format(year = year): november,'{year}-12-01'.format(year = year): december}).replace(\"-\",\" \"))\n",
    "\n",
    "#compile the list of dataframes into a single dataframe, only keeping the makes and models contained in all years\n",
    "car_sales = reduce(lambda left, right:\n",
    "               pd.merge(left, right, on = 'make_and_model', how = 'outer'),\n",
    "               carsaleslist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section is where we merge the Car Model list with the car sales dataframe to allow us to assign a body-type to each of the car models that we have sales data for"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "'''This section of the code will merge the car_sales data with the car_models data, such that every car make and model\n",
    "sold will be placed in a car body category'''\n",
    "#Read the car model csv file containing the body size category of many different car makes and models\n",
    "car_models = pd.read_csv(\"Data CSVs/Car_Model_List.csv\")\n",
    "#read a hand-generated csv containing the models missing from the main model list but contained in the car_sales dataframe\n",
    "missing_car_models = pd.read_csv(\"Data CSVs/missing_models.csv\")\n",
    "\n",
    "#create a list of the months considered in this analysis\n",
    "months_for_analysis = ['2019-01-01', '2019-02-01', '2019-03-01', '2019-04-01', '2019-05-01', '2019-06-01','2019-07-01',\n",
    "                       '2019-08-01', '2019-09-01', '2019-10-01', '2019-11-01', '2019-12-01',\n",
    "                       '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01', '2020-07-01',\n",
    "                       '2020-08-01', '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01',\n",
    "                       '2021-01-01', '2021-02-01', '2021-03-01', '2021-04-01', '2021-05-01', '2021-06-01', '2021-07-01',\n",
    "                       '2021-08-01', '2021-09-01', '2021-10-01', '2021-11-01', '2021-12-01']\n",
    "\n",
    "\n",
    "def make_and_model_canonicalization(car_sales, car_models,missing_car_models):\n",
    "    '''Canonicalizes car_sales such that the elements in the make_and_model column of both dataframes matches\n",
    "        input:\n",
    "        car_sales --> A dataframe containing monthly car sales for different makes and models\n",
    "        car_models --> A dataframe containing different car makes and models and their body\n",
    "\n",
    "        returns:\n",
    "        car_models dataset with modified strings in the make_and_model column to match the car_sales column canonicalization\n",
    "        car_sales dataset with modified strings in the make_and_model column to match the car_models column canonicalization\n",
    "        '''\n",
    "    car_make_list = car_models[\"Make\"].astype(str).str.lower().str.replace(\"-benz\",\"\").unique().tolist()\n",
    "    # Creating a single column for make and model, to match the format of the car_sales column\n",
    "    car_models[\"make_and_model\"] = car_models[\"Make\"].astype(str).str.lower() + \" \" + car_models[\"Model\"].astype(str).str.lower().replace(car_make_list,\" \",regex=True)\n",
    "\n",
    "    # Removing duplicates since the same make and model is present for multiple years in the car_models dataframe\n",
    "    car_models = car_models.loc[:, [\"make_and_model\", \"Category\"]].drop_duplicates().apply(lambda x: x.replace(\"-\",\" \",regex=True)\n",
    "                                                                                           .replace(\"/\",\" \",regex=True)\n",
    "                                                                                           .replace(\"benz\",\" \",regex=True)\n",
    "                                                                                           .replace(\"bolt ev\",\"bolt\",regex=True)\n",
    "                                                                                           .replace(\"passenger\",\" \",regex=True)\n",
    "                                                                                           .replace(\"crew cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"extended cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"regular cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"1500 double cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"2500 hd double cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"2500 cargo\",\" \",regex=True)\n",
    "                                                                                           .replace(\"2500 hd\",\" \",regex=True)\n",
    "                                                                                           .replace(\"3500 hd\",\" \",regex=True)\n",
    "                                                                                           .replace(\"1500\",\" \",regex=True)\n",
    "                                                                                           .replace(\"fuel cell\",\"fcv\",regex=True)\n",
    "                                                                                           .replace(\"electric\",\" \",regex=True)\n",
    "                                                                                           .replace(\"boxster\",\" \",regex=True)\n",
    "                                                                                           .replace(\"defender 90\",\"defender\",regex=True)\n",
    "                                                                                           .replace(\"slc class\",\"slc\",regex=True))\n",
    "    car_models[\"make_and_model\"] = car_models[\"make_and_model\"] \\\n",
    "        .apply(lambda x: x[:12] if (\"ford transit\" in x and \"ford transit connect\" not in x) else x)\\\n",
    "        .apply(lambda x: \"ford f series\" if \"ford f150\" in x else x)\\\n",
    "        .apply(lambda x: \"ford e series\" if \"ford e350\" in x else x)\n",
    "\n",
    "    car_sales[\"make_and_model\"] = car_sales[\"make_and_model\"].str.lower()\n",
    "    car_models[\"Category\"] = car_models[\"Category\"].replace(\"1992\",\"\",regex=True).replace(\"2020\",\"\",regex=True)\n",
    "\n",
    "    car_sales = car_sales.apply(lambda x: x.replace(\"-\", \" \",regex=True)\n",
    "                                .replace(\"/\", \" \",regex=True)\n",
    "                                .replace(\"lr4\",\" \",regex=True)\n",
    "                                .replace(\"impreza wrx\",\"wrx\",regex=True)\n",
    "                                .replace(\"fr s\",\" \",regex=True)\n",
    "                                .replace(\"benz\",\" \",regex=True)\n",
    "                                .replace(\"etron\",\"e tron\",regex=True)\n",
    "                                .replace(\"tuscon\",\"tucson\",regex=True)\n",
    "                                .replace(\"mazda3\",\"mazda 3\",regex=True)\n",
    "                                .replace(\"mazda6\",\"mazda 6\",regex=True)\n",
    "                                .replace(\"nautilus\",\" \",regex=True)\n",
    "                                .replace(\"90 series\",\"s90\",regex=True)\n",
    "                                .replace(\"60 series\",\"s60\",regex=True)\n",
    "                                .replace(\"40 series\",\"s40\",regex=True)\n",
    "                                .replace(\"pickup\",\" \",regex=True)\n",
    "                                .replace(\"family\",\" \",regex=True)\n",
    "                                .replace(\"glk class\",\" \",regex=True)\n",
    "                                .replace(\"gl gls class\",\"gls\",regex=True)\n",
    "                                .replace(\"gle class\",\"gle\",regex=True)\n",
    "                                .replace(\"slc class\",\"slc\",regex=True)\n",
    "                                .replace(\"e   cls class\",\"cls\",regex=True))\n",
    "\n",
    "    #Removing additional spaces in the strings in the male_and_model column\n",
    "    car_sales[\"make_and_model\"] = car_sales[\"make_and_model\"].apply(lambda x:' '.join(x.split()))\n",
    "    car_models[\"make_and_model\"] = car_models[\"make_and_model\"].apply(lambda x:' '.join(x.split()))\n",
    "    car_models = pd.concat([car_models, missing_car_models], axis=0)\n",
    "\n",
    "    return car_sales,car_models\n",
    "\n",
    "#Merging car_sales and car_models by make and model\n",
    "car_sales, car_models = make_and_model_canonicalization(car_sales, car_models,missing_car_models)\n",
    "car_sales_by_size = car_sales.merge(right=car_models,\n",
    "                                    how='outer',\n",
    "                                    on='make_and_model')\n",
    "\n",
    "#Filters out the vehicle makes and models that were not sold in any month from 2019-2021 in Canada\n",
    "car_sales_by_size = car_sales_by_size[~car_sales_by_size[months_for_analysis].isna().all(1) | (car_sales_by_size[months_for_analysis]==0).all(1)]\n",
    "\n",
    "#Drop duplicate rows\n",
    "car_sales_by_size = car_sales_by_size.drop_duplicates(['make_and_model'])\n",
    "\n",
    "#put car model, car sales, and merged car sales list  to csv\n",
    "car_models.to_csv('Output CSVs/Car_Model_List_updated.csv', encoding='utf-8', index=False)\n",
    "car_sales.to_csv('Output CSVs/Car_Sales_2019_2021.csv', encoding='utf-8', index=False)\n",
    "car_sales_by_size.to_csv('Output CSVs/Merged Car Sales List.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#Now combining all the data into one table\n",
    "\n",
    "#categorizing all combinations of car size category\n",
    "small_cars=[\"Coupe\",\"Hatchback\",\"Convertible\",'Convertible, Sedan','Coupe, Sedan, Convertible',\n",
    "            'Coupe, Convertible','Convertible, Sedan, Coupe','Sedan, Hatchback','Hatchback, Sedan',\n",
    "            'Hatchback, Sedan, Coupe','Convertible, Coupe, Hatchback']\n",
    "midsize_cars=[\"SUV\",\"Sedan\",\"Wagon\",'Wagon, Sedan']\n",
    "large_cars=[\"Pickup\",\"Van\",\"Minivan\",'Van Minivan']\n",
    "\n",
    "#categorizing the sizes\n",
    "car_sales_by_size['Category'] = car_sales_by_size['Category']\\\n",
    "    .apply(lambda x: 'small' if (x in small_cars) else x)\\\n",
    "    .apply(lambda x: 'midsize' if (x in midsize_cars) else x)\\\n",
    "    .apply(lambda x: 'large' if (x in large_cars) else x)\n",
    "\n",
    "#create a new dataframe with categorized % columns\n",
    "car_size_category = car_sales_by_size.groupby('Category').agg(sum)\n",
    "\n",
    "\n",
    "#create monthly sums list that represents the total sales for each month of different car sizes\n",
    "monthly_sums = list(car_sales_by_size.sum(axis = 0)[1:-1])\n",
    "\n",
    "#calculate % proportion sales for each size of car per month\n",
    "car_size_category = (car_size_category/monthly_sums).T.rename(columns={\"small\": \"prop_small\",\n",
    "                                                                       \"midsize\": \"prop_midsize\",\n",
    "                                                                       \"large\": \"prop_large\"})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we add all the other features we consider to the dataframe, including:\n",
    "- monthly employment stats (with corrected units as per website indication\n",
    "- monthly oil prices\n",
    "- monthly transit ridership stats\n",
    "- monthly dollar exchange rate (with respect to USD)\n",
    "- monthly gdp for canada\n",
    "- monthly interest rate from the bank of canada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#convert to datetime index full month name and full year\n",
    "car_size_category.index = pd.to_datetime(car_size_category.reset_index()['index'])\n",
    "\n",
    "#add the monthly total sales figures as a feature\n",
    "car_size_category['Total Monthly Car Sales'] = monthly_sums\n",
    "car_size_category.to_csv('Output CSVs/%_category.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "#add the monthly employment stats units corrected (x1000) and datetime index set as a feature\n",
    "employment_stats = pd.read_csv(\"Data CSVs/monthly_employment_stats_2019-2021.csv\").set_index('Labour force characteristics')\\\n",
    "    .T.astype(str).replace(',','',regex = True).astype(float)\n",
    "employment_stats.index = employment_stats.reset_index()['index'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "employment_stats[['Unemployment rate','Participation rate','Employment rate']]= employment_stats[['Unemployment rate','Participation rate','Employment rate']]/100\n",
    "employment_stats[employment_stats.columns.difference(['Unemployment rate','Participation rate','Employment rate'])]\\\n",
    "    =employment_stats[employment_stats.columns.difference(['Unemployment rate','Participation rate','Employment rate'])]*1000\n",
    "\n",
    "\n",
    "#Add the monthly oil prices units corrected (cents to dollars) and datetime index set as a feature\n",
    "oil_prices = pd.read_csv(\"Data CSVs/monthly_oil_prices_2019-2021.csv\").rename(columns={\"VALUE\": \"Average Monthly Oil Price\"})\\\n",
    "                 .set_index('REF_DATE').loc[:,'Average Monthly Oil Price'].astype(float)/100\n",
    "oil_prices.index = oil_prices.reset_index()['REF_DATE'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "\n",
    "#add the monthly transit ridership units corrected (x1 mill) and datetime index set as a feature\n",
    "transit_ridership = pd.read_csv(\"Data CSVs/monthly_transit_ridership_2019-2021.csv\").rename(columns={\"VALUE\": \"transit_ridership\"})\\\n",
    "                        .set_index('REF_DATE').loc[:,'transit_ridership'].astype(float)*1000000\n",
    "transit_ridership.index = transit_ridership.reset_index()['REF_DATE'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "\n",
    "#add the monthly dollar exchange rate (USD-CAD) datetime index set as a feature\n",
    "der_usd_cad = pd.read_csv(\"Data CSVs/monthly_der_2019-2021.csv\").rename(columns={\"FXMUSDCAD\": \"Dollar Exchange Rate\"})\\\n",
    "                        .set_index('date').loc[:,'Dollar Exchange Rate'].astype(float)\n",
    "der_usd_cad.index = der_usd_cad.reset_index()['date'].apply(lambda x: datetime.strptime(x,\"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "#add the monthly gdp (in 2012 dollars) units correct and datetime index set as a feature\n",
    "gdp = pd.read_csv(\"Data CSVs/monthly_gdp_2019-2021.csv\").rename(columns={\"VALUE\": \"gdp\"})\\\n",
    "                 .set_index('REF_DATE').loc[:,'gdp'].astype(float)*1000000\n",
    "gdp.index = gdp.reset_index()['REF_DATE'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "\n",
    "#add the monthly interest rates as a feature\n",
    "interest_rates = pd.read_csv('Data CSVs/monthly_interest_rates_canada.csv')\n",
    "interest_rates['Date'] = pd.to_datetime(interest_rates['Date'])\n",
    "interest_rates.set_index('Date', drop = True, inplace= True)\n",
    "\n",
    "#merging all dataframes into using datetime indices\n",
    "total_table = pd.concat([car_size_category,employment_stats,oil_prices,transit_ridership, der_usd_cad, gdp, interest_rates], axis=1)\n",
    "total_table.to_csv('Output CSVs/Merged Total Table.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#add the season of the year as a feature\n",
    "#This dictionary maps each month to a season (Canadian Seasons) where 1 is Summer, 2 is Fall, 3 is Winter and 4 is Spring\n",
    "ref_seasons = {12:3, 1:3, 2:3,\n",
    "           3:4, 4:4, 5:4,\n",
    "           6:1, 7:1, 8:1,\n",
    "           9:2, 10:2,11:2}\n",
    "total_table['Season'] = total_table.index.month\n",
    "total_table['Season'] = total_table['Season'].apply(lambda x : ref_seasons[x])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "            prop_large  prop_midsize  prop_small  Total Monthly Car Sales  \\\n2019-01-01    0.275133      0.618239    0.106629                 110852.0   \n2019-02-01    0.267699      0.634983    0.097318                 123060.0   \n2019-03-01    0.247631      0.639159    0.113210                 183438.0   \n2019-04-01    0.259242      0.630051    0.110707                 182401.0   \n2019-05-01    0.260068      0.619245    0.120687                 201728.0   \n\n            Population  Labour force  Employment  Full-time employment  \\\n2019-01-01  30479800.0    20004100.0  18822200.0            15214700.0   \n2019-02-01  30507800.0    20063500.0  18876400.0            15273700.0   \n2019-03-01  30542600.0    20031200.0  18861700.0            15278100.0   \n2019-04-01  30589000.0    20129400.0  18971200.0            15355800.0   \n2019-05-01  30630400.0    20082400.0  19004300.0            15394700.0   \n\n            Part-time employment  Unemployment  Unemployment rate  \\\n2019-01-01             3607500.0     1181900.0              0.059   \n2019-02-01             3602600.0     1187100.0              0.059   \n2019-03-01             3583600.0     1169600.0              0.058   \n2019-04-01             3615400.0     1158200.0              0.058   \n2019-05-01             3609700.0     1078100.0              0.054   \n\n            Participation rate  Employment rate  Average Monthly Oil Price  \\\n2019-01-01               0.656            0.618                      1.031   \n2019-02-01               0.658            0.619                      1.051   \n2019-03-01               0.656            0.618                      1.177   \n2019-04-01               0.658            0.620                      1.295   \n2019-05-01               0.656            0.620                      1.307   \n\n            transit_ridership  Dollar Exchange Rate           gdp  \\\n2019-01-01        160900000.0                1.3301  1.965814e+12   \n2019-02-01        153800000.0                1.3206  1.962068e+12   \n2019-03-01        164700000.0                1.3368  1.974461e+12   \n2019-04-01        157300000.0                1.3378  1.981670e+12   \n2019-05-01        155300000.0                1.3459  1.987070e+12   \n\n            Interest Rate  Season  \n2019-01-01            2.0       3  \n2019-02-01            2.0       3  \n2019-03-01            2.0       4  \n2019-04-01            2.0       4  \n2019-05-01            2.0       4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prop_large</th>\n      <th>prop_midsize</th>\n      <th>prop_small</th>\n      <th>Total Monthly Car Sales</th>\n      <th>Population</th>\n      <th>Labour force</th>\n      <th>Employment</th>\n      <th>Full-time employment</th>\n      <th>Part-time employment</th>\n      <th>Unemployment</th>\n      <th>Unemployment rate</th>\n      <th>Participation rate</th>\n      <th>Employment rate</th>\n      <th>Average Monthly Oil Price</th>\n      <th>transit_ridership</th>\n      <th>Dollar Exchange Rate</th>\n      <th>gdp</th>\n      <th>Interest Rate</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01</th>\n      <td>0.275133</td>\n      <td>0.618239</td>\n      <td>0.106629</td>\n      <td>110852.0</td>\n      <td>30479800.0</td>\n      <td>20004100.0</td>\n      <td>18822200.0</td>\n      <td>15214700.0</td>\n      <td>3607500.0</td>\n      <td>1181900.0</td>\n      <td>0.059</td>\n      <td>0.656</td>\n      <td>0.618</td>\n      <td>1.031</td>\n      <td>160900000.0</td>\n      <td>1.3301</td>\n      <td>1.965814e+12</td>\n      <td>2.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2019-02-01</th>\n      <td>0.267699</td>\n      <td>0.634983</td>\n      <td>0.097318</td>\n      <td>123060.0</td>\n      <td>30507800.0</td>\n      <td>20063500.0</td>\n      <td>18876400.0</td>\n      <td>15273700.0</td>\n      <td>3602600.0</td>\n      <td>1187100.0</td>\n      <td>0.059</td>\n      <td>0.658</td>\n      <td>0.619</td>\n      <td>1.051</td>\n      <td>153800000.0</td>\n      <td>1.3206</td>\n      <td>1.962068e+12</td>\n      <td>2.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2019-03-01</th>\n      <td>0.247631</td>\n      <td>0.639159</td>\n      <td>0.113210</td>\n      <td>183438.0</td>\n      <td>30542600.0</td>\n      <td>20031200.0</td>\n      <td>18861700.0</td>\n      <td>15278100.0</td>\n      <td>3583600.0</td>\n      <td>1169600.0</td>\n      <td>0.058</td>\n      <td>0.656</td>\n      <td>0.618</td>\n      <td>1.177</td>\n      <td>164700000.0</td>\n      <td>1.3368</td>\n      <td>1.974461e+12</td>\n      <td>2.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2019-04-01</th>\n      <td>0.259242</td>\n      <td>0.630051</td>\n      <td>0.110707</td>\n      <td>182401.0</td>\n      <td>30589000.0</td>\n      <td>20129400.0</td>\n      <td>18971200.0</td>\n      <td>15355800.0</td>\n      <td>3615400.0</td>\n      <td>1158200.0</td>\n      <td>0.058</td>\n      <td>0.658</td>\n      <td>0.620</td>\n      <td>1.295</td>\n      <td>157300000.0</td>\n      <td>1.3378</td>\n      <td>1.981670e+12</td>\n      <td>2.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2019-05-01</th>\n      <td>0.260068</td>\n      <td>0.619245</td>\n      <td>0.120687</td>\n      <td>201728.0</td>\n      <td>30630400.0</td>\n      <td>20082400.0</td>\n      <td>19004300.0</td>\n      <td>15394700.0</td>\n      <td>3609700.0</td>\n      <td>1078100.0</td>\n      <td>0.054</td>\n      <td>0.656</td>\n      <td>0.620</td>\n      <td>1.307</td>\n      <td>155300000.0</td>\n      <td>1.3459</td>\n      <td>1.987070e+12</td>\n      <td>2.0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_table.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preliminary Exploratory Data Analysis - Looking into inter-correlations between features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot and initial correlation heatmap of all included variables to identify which ones to remove (highly inter-correlated variables)\n",
    "correlation=total_table.corr()\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.title('Correlation Heatmap of Vehicle Sales in Canada Dataset')\n",
    "ax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=30)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the heatmap above, it is clear that some features are highly correlated with each other. The features that stand out are the socio-economic indicators that relate to job status (i.e. employment, employment rates, unemployment). This makes sense because these indicators are all tied to each other (i.e. unemployment rate is directly tied to employment rate etc.). For this reason, selected features will be excluded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_to_exclude = [\n",
    "                       'Total Monthly Car Sales',\n",
    "                       'Population',\n",
    "                       'Labour force',\n",
    "                       'Employment',\n",
    "                       'Full-time employment',\n",
    "                       'Part-time employment',\n",
    "                       'Unemployment',\n",
    "                       'Unemployment rate',\n",
    "                       'Participation rate',\n",
    "                       #'Employment rate',\n",
    "                       #'Average Monthly Oil Price',\n",
    "                       'transit_ridership',\n",
    "                       #'Dollar Exchange Rate',\n",
    "                       'gdp',\n",
    "                       #'Interest Rate',\n",
    "                       #'Season'\n",
    "                       ]\n",
    "model_table = total_table.drop(features_to_exclude, axis = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "New feature correlation visualizations after feature selection\n",
    "\n",
    "This section produces several graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot a correlation heatmap between the selected variables\n",
    "correlation=model_table.drop(['prop_small','prop_midsize','prop_large'],axis=1).corr()\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "ax=sns.heatmap(correlation,square=True,annot=True,fmt='.2f',linecolor='white')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(),rotation=30)\n",
    "plt.show()\n",
    "\n",
    "#Plot interest rates over time\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.title('Monthly Interest Rates and Total Monthly Sales over Time',fontsize=20)\n",
    "ax=sns.lineplot(x=total_table.index,y=total_table['Interest Rate'],color='steelblue')\n",
    "ax.set_xlabel('Month',fontsize=18)\n",
    "ax.set_ylabel('Interest Rate',fontsize=18,color='steelblue')\n",
    "\n",
    "#Plot total monthly vehicle sales over time on the same plot\n",
    "ax2=ax.twinx()\n",
    "sns.lineplot(x=total_table.index,y=total_table['Total Monthly Car Sales'],ax=ax2,color='red')\n",
    "ax2.set_ylabel('Total Monthly Vehicle Sales',fontsize=18,color='red')\n",
    "plt.show()\n",
    "\n",
    "#Plot sales over time with respect to season\n",
    "#1 is summer, 2 is fall, 3 is winter, 4 is spring\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.xlim(total_table.index.min(),total_table.index.max())\n",
    "plt.ylim(total_table['Total Monthly Car Sales'].min(),total_table['Total Monthly Car Sales'].max())\n",
    "plt.title('Monthly Car Sales With Seasons',fontsize=20)\n",
    "ax=sns.scatterplot(x=total_table.index,y=total_table['Total Monthly Car Sales'],hue=total_table['Season'],markers='o',s=200,palette=sns.color_palette(\"husl\",4))\n",
    "\n",
    "#adds a line over dot markers for the seasons plot\n",
    "sns.lineplot(x=total_table.index,y=total_table['Total Monthly Car Sales'],color='black',ax=ax)\n",
    "ax.set_xlabel('Month',fontsize=18)\n",
    "ax.set_ylabel('Total Monthly Car Sales',fontsize=18)\n",
    "h,l=ax.get_legend_handles_labels()\n",
    "plt.legend(h[12:15],l[12:15])\n",
    "plt.show()\n",
    "\n",
    "#Plot proportion of sales over time with respect to seasons\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.title('Proportion of Total Sales over Time',fontsize=20)\n",
    "ax=sns.scatterplot(x=total_table.index,y=total_table['prop_small'],hue=total_table['Season'],palette=sns.color_palette(\"husl\",4),s=200)\n",
    "sns.scatterplot(x=total_table.index,y=total_table['prop_midsize'],hue=total_table['Season'],palette=sns.color_palette(\"husl\",4),s=200,ax=ax)\n",
    "sns.scatterplot(x=total_table.index,y=total_table['prop_large'],hue=total_table['Season'],palette=sns.color_palette(\"husl\",4),s=200,ax=ax)\n",
    "ax.set_xlabel('Month',fontsize=18)\n",
    "ax.set_ylabel('Proportion of Total Monthly Car Sales',fontsize=18)\n",
    "\n",
    "#adds a line over the dot markers for each of the proportions\n",
    "sns.lineplot(x=total_table.index,y=total_table['prop_small'],label='Small',ax=ax)\n",
    "sns.lineplot(x=total_table.index,y=total_table['prop_midsize'],label='Midsize',ax=ax)\n",
    "sns.lineplot(x=total_table.index,y=total_table['prop_large'],label='Large',ax=ax)\n",
    "\n",
    "#updates the legend with the correct seasons\n",
    "#3 is winter,4 is spring,1 is summer,2 is fall\n",
    "h,l=ax.get_legend_handles_labels()\n",
    "lbls=['Summer','Fall','Winter','Spring','Small','Midsize','Large']\n",
    "plt.legend(h[8:15],lbls,title='Legend')\n",
    "\n",
    "\n",
    "#this loop plots each explanatory variable over the monthly proportions graph (on separate y-axes)\n",
    "iter = 0\n",
    "for column in model_table.columns:\n",
    "    #this iterable skips over the first few plots in the dataset because they are irrelevant (proportions, not explanatory variables)\n",
    "    iter += 1\n",
    "    if iter < 4 : continue\n",
    "    plt.figure(figsize=(18,12))\n",
    "    plt.title('Proportion of Total Sales over Time and {}'.format(column),fontsize=25)\n",
    "    ax=sns.scatterplot(x=model_table.index,y=model_table['prop_small'],hue=model_table['Season'],palette=sns.color_palette(\"husl\",4),s=200)\n",
    "    sns.scatterplot(x=model_table.index,y=model_table['prop_midsize'],hue=model_table['Season'],palette=sns.color_palette(\"husl\",4),s=200,ax=ax)\n",
    "    sns.scatterplot(x=model_table.index,y=model_table['prop_large'],hue=model_table['Season'],palette=sns.color_palette(\"husl\",4),s=200,ax=ax)\n",
    "    ax.set_xlabel('Month',fontsize=18)\n",
    "    ax.set_ylabel('Proportion of Total Monthly Car Sales',fontsize=18)\n",
    "\n",
    "    #adds a line over the markers for each proportion\n",
    "    sns.lineplot(x=model_table.index,y=model_table['prop_small'],label='Small',ax=ax)\n",
    "    sns.lineplot(x=model_table.index,y=model_table['prop_midsize'],label='Midsize',ax=ax)\n",
    "    sns.lineplot(x=model_table.index,y=model_table['prop_large'],label='Large',ax=ax)\n",
    "\n",
    "    #plots the selected feature over the proportions plot\n",
    "    ax2 = ax.twinx()\n",
    "    sns.lineplot(x=model_table.index,y=model_table[column],ax=ax2,color='Black')\n",
    "    ax2.set_ylabel(column,fontsize=18,color='Black')\n",
    "    ax.legend().remove()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section is where we develop our model using the features we have selected. We have chosen to use a linear regression model to predict the proportions of vehicle sales for each of the three car size categories we have identified (small, midsize and large).\n",
    "\n",
    "First the data is split into a train and test dataset. Because the data is timeseries data, the test data is kept as the last 30% (11 rows) in the table and the train data is set as the first 70%. This is because training a model on data after the test set is counter-intuitive and would not occur in the real use-case (i.e. you can't use data from the future).\n",
    "\n",
    "Next the data is scaled using the min-max scaler (to fall between 0 and 1).\n",
    "\n",
    "Three linear regression models are then initialized (one for each car size category)\n",
    "\n",
    "Using a timeseries cross validation method, the training data is then split into 5 CV folds (with the same restriction on data only being allowed to be used to train the model from before the validation set) and for each fold, the models are trained on the train data set and evaluated on the validation data. The root mean squared error (the metric used to score the models in this analysis) are then compiled into a new dataframe.\n",
    "\n",
    "The models are then run on the test data set and the results added to the result-storing dataframe.\n",
    "\n",
    "The results for this specific selection of features can then be stored in a separate CSV file, including the RMSE's for the training data, validation and the features used to train the models.\n",
    "\n",
    "In addition to changing features, we also analysed how our models performed when trained and tested on data entirely from before covid (pre-pandemic data). The range of this data has been determined to be between January 2019 and March 2020. To train our model on this data, we modify the table from which we generate our train-test splits to drop the dates corresponding to pandemic-affected data and run the model on the new (much smaller) dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#For analysis on pre-pandemic data, and excluding pandemic dates from the beginning of the pandemic in March 2020 until December 2021, when there was a 0% change in Canadian GDP and after which GDP stabilized, use the pre_pandemic_table instead of the model_table\n",
    "#https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2020009-eng.htm\n",
    "pandemic_dates = pd.to_datetime([\"2020-03-01\",\"2020-04-01\",\"2020-05-01\",\"2020-06-01\",\"2020-07-01\",\"2020-08-01\"\n",
    "                                    ,\"2020-09-01\",\"2020-10-01\",\"2020-11-01\",\"2020-12-01\",\"2021-01-01\",\"2021-02-01\",\n",
    "                                 \"2021-03-01\",\"2021-04-01\",\"2021-05-01\",\"2021-06-01\",\"2021-07-01\",\"2021-08-01\"\n",
    "                                    ,\"2021-09-01\",\"2021-10-01\",\"2021-11-01\",\"2021-12-01\"])\n",
    "#this table is a modified version of the table containing all data used in this model and only contains rows from before the pandemic\n",
    "pre_pandemic_table = model_table.drop(pandemic_dates)\n",
    "\n",
    "#Splitting data into train and test splits, taking the last 30% of the data as the test data\n",
    "####use pre-pandemic_table for pre-pandemic modelling and model_table for all months####\n",
    "train_split_size = 0.7\n",
    "train = model_table.iloc[0:int(len(model_table)*train_split_size),:]\n",
    "test = model_table.iloc[int(len(model_table)*train_split_size):,:]\n",
    "\n",
    "#Verify that data was split correctly\n",
    "print('Train data is  {percent:.2f}% of whole dataset'.format(percent = train.shape[0] / model_table.shape[0] * 100))\n",
    "print('Test data is  {percent:.2f}% of whole dataset'.format(percent = test.shape[0] / model_table.shape[0] * 100))\n",
    "\n",
    "#this function splits the data from the whole table into the sections required for each model\n",
    "def process_data(data):\n",
    "    \"\"\"Process the data for the guided model, which will predict the proportion of small, midsize, and\n",
    "    large vehicles sold in Canada.\n",
    "        Input: data --> dataframe with x and y values\n",
    "        Output: X --> explanatory variables\n",
    "                y_small --> proportion of small vehicles purchased\n",
    "                y_midsize --> proportion of midsize vehicles purchased\n",
    "                y_large --> proportion of large vehicles purchased\n",
    "    \"\"\"\n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['prop_small','prop_midsize','prop_large'], axis=1)\n",
    "    y_small = data.loc[:, 'prop_small']\n",
    "    y_midsize = data.loc[:, 'prop_midsize']\n",
    "    y_large = data.loc[:, 'prop_large']\n",
    "\n",
    "    return X, y_small, y_midsize, y_large\n",
    "\n",
    "#Separating data into training, validation, and test datasets\n",
    "X_train, y_train_small, y_train_midsize, y_train_large = process_data(train)\n",
    "X_test, y_test_small, y_test_midsize, y_test_large = process_data(test)\n",
    "\n",
    "#Scaling variables based on minimum and maximum values to be within 0 and 1\n",
    "cols = X_train.columns\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#rebuild the dataframes from the scaled data\n",
    "X_train = pd.DataFrame(X_train, columns = cols)\n",
    "X_test = pd.DataFrame(X_test, columns = cols)\n",
    "\n",
    "#Training linear regression models for small, midsize, and large vehicle sales\n",
    "linear_model_small = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_midsize = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_large = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "#time series cross validation of the train dataset (splits train dataset further into train and validation)\n",
    "results = []\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, val_index in tscv.split(X_train):\n",
    "    #sets the train and validation datasets to the indexes allocated by the CV splitter\n",
    "    X_training, X_val = X_train.iloc[train_index,:], X_train.iloc[val_index,:]\n",
    "    y_training_small, y_training_midsize, y_training_large = y_train_small.iloc[train_index], y_train_midsize.iloc[train_index], y_train_large.iloc[train_index]\n",
    "    y_val_small, y_val_midsize, y_val_large = y_train_small.iloc[val_index], y_train_midsize.iloc[val_index], y_train_large.iloc[val_index]\n",
    "\n",
    "    #fit the models for each fold\n",
    "    linear_model_small.fit(X_training, y_training_small)\n",
    "    linear_model_midsize.fit(X_training, y_training_midsize)\n",
    "    linear_model_large.fit(X_training, y_training_large)\n",
    "\n",
    "    #predict proportions based on training dataset\n",
    "    y_train_small_predicted = linear_model_small.predict(X_training)\n",
    "    y_train_midsize_predicted = linear_model_midsize.predict(X_training)\n",
    "    y_train_large_predicted = linear_model_large.predict(X_training)\n",
    "\n",
    "    #predict proportions based on validation dataset\n",
    "    y_val_small_predicted = linear_model_small.predict(X_val)\n",
    "    y_val_midsize_predicted = linear_model_midsize.predict(X_val)\n",
    "    y_val_large_predicted = linear_model_large.predict(X_val)\n",
    "\n",
    "    #calculate and append training and validation RMSE for each fold to a results list\n",
    "    results.append([mean_squared_error(y_training_small, y_train_small_predicted, squared = False),\n",
    "                    mean_squared_error(y_training_midsize, y_train_midsize_predicted, squared = False),\n",
    "                    mean_squared_error(y_training_large, y_train_large_predicted, squared = False),\n",
    "                    mean_squared_error(y_val_small, y_val_small_predicted, squared = False),\n",
    "                    mean_squared_error(y_val_midsize, y_val_midsize_predicted, squared = False),\n",
    "                    mean_squared_error(y_val_large, y_val_large_predicted, squared = False)])\n",
    "\n",
    "#convert list of RMSE's for each fold into a dataframe for easier access\n",
    "errors = pd.DataFrame(results, columns = ['train_small', 'train_midsize', 'train_large', 'val_small', 'val_midsize', 'val_large'])\n",
    "\n",
    "\n",
    "# Printing calculated error values for the validation sets of the three models\n",
    "print('\\n')\n",
    "print('Mean Training RMSE for small cars model: {:.2f}%'.format(errors['train_small'].mean()*100))\n",
    "print('Mean Training RMSE for midsize cars model: {:.2f}%'.format(errors['train_midsize'].mean()*100))\n",
    "print('Mean Training RMSE for large cars model: {:.2f}%'.format(errors['train_large'].mean()*100))\n",
    "print('\\n')\n",
    "print('Mean Validation RMSE for small cars model: {:.2f}%'.format(errors['val_small'].mean()*100))\n",
    "print('Mean Validation RMSE for midsize cars model: {:.2f}%'.format(errors['val_midsize'].mean()*100))\n",
    "print('Mean Validation RMSE for large cars model: {:.2f}%'.format(errors['val_large'].mean()*100))\n",
    "print('\\n')\n",
    "print('Test RMSE for small cars model: {:.2f}%'.format(mean_squared_error(y_test_small, linear_model_small.predict(X_test), squared = False)*100))\n",
    "print('Test RMSE for midsize cars model: {:.2f}%'.format(mean_squared_error(y_test_midsize, linear_model_midsize.predict(X_test), squared = False)*100))\n",
    "print('Test RMSE for large cars model: {:.2f}%'.format(mean_squared_error(y_test_large, linear_model_large.predict(X_test), squared = False)*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section saves the list of features and the model RMSE values for that list of features to an external csv for comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_results = pd.read_csv('Output CSVs/model_results.csv')\n",
    "this_results = []\n",
    "this_results.append([list(X_train.columns),\n",
    "                     errors['train_small'].mean()*100,\n",
    "                     errors['train_midsize'].mean()*100,\n",
    "                     errors['train_large'].mean()*100,\n",
    "                     errors['val_small'].mean()*100,\n",
    "                     errors['val_midsize'].mean()*100,\n",
    "                     errors['val_large'].mean()*100,\n",
    "                     mean_squared_error(y_test_small, linear_model_small.predict(X_test), squared = False)*100,\n",
    "                     mean_squared_error(y_test_midsize, linear_model_midsize.predict(X_test), squared = False)*100,\n",
    "                     mean_squared_error(y_test_large, linear_model_large.predict(X_test), squared = False)*100]\n",
    "                    )\n",
    "this_results = pd.DataFrame(this_results, columns = ['Features List',\n",
    "                                     'Mean RMSE small train',\n",
    "                                     'Mean RMSE midsize train',\n",
    "                                     'Mean RMSE large train',\n",
    "                                     'Mean RMSE small val',\n",
    "                                     'Mean RMSE midsize val',\n",
    "                                     'Mean RMSE large val',\n",
    "                                     'RMSE small test',\n",
    "                                     'RMSE midsize test',\n",
    "                                     'RMSE large test'])\n",
    "model_results = pd.concat([model_results, this_results], axis = 0)\n",
    "model_results.to_csv('Output CSVs/model_results.csv', encoding='utf-8', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
