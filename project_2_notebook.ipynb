{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Welcome to our Project 2 Notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from requests import get\n",
    "from functools import reduce\n",
    "\n",
    "# Configure Notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we scrape the GoodCarBadCar website to produce tables from which we can form our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "years = [2019, 2020, 2021]\n",
    "ranges = [594, 1, 580]\n",
    "carsaleslist = []\n",
    "\n",
    "for index, year in enumerate(years):\n",
    "    response = get('https://www.goodcarbadcar.net/{year}-canada-vehicle-sales-figures-by-model/' .format(year = year))\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table_rows = html_soup.find_all('tr')[ranges[index]:-1] #excludes the sum row\n",
    "\n",
    "    model_names = []\n",
    "    january = []\n",
    "    february = []\n",
    "    march = []\n",
    "    april = []\n",
    "    may = []\n",
    "    june = []\n",
    "    july = []\n",
    "    august = []\n",
    "    september = []\n",
    "    october = []\n",
    "    november = []\n",
    "    december = []\n",
    "\n",
    "    # iterate through each row in the table\n",
    "    for row in table_rows:\n",
    "        # use certain tags positions and/or subtags, then extract the text, and use .strip() to remove leading whitespace, and then add them to the corresponding to list\n",
    "        model_name = row.find_all('td')[0].text.strip()\n",
    "        model_names.append(model_name)\n",
    "\n",
    "        jan_sum = row.find_all('td')[1].text.strip()\n",
    "        january.append(int(jan_sum.replace(',','')))\n",
    "\n",
    "        feb_sum = row.find_all('td')[2].text.strip()\n",
    "        february.append(int(feb_sum.replace(',','')))\n",
    "\n",
    "        mar_sum = row.find_all('td')[3].text.strip()\n",
    "        march.append(int(mar_sum.replace(',','')))\n",
    "\n",
    "        apr_sum = row.find_all('td')[4].text.strip()\n",
    "        april.append(int(apr_sum.replace(',','')))\n",
    "\n",
    "        may_sum = row.find_all('td')[5].text.strip()\n",
    "        may.append(int(may_sum.replace(',','')))\n",
    "\n",
    "        jun_sum = row.find_all('td')[6].text.strip()\n",
    "        june.append(int(jun_sum.replace(',','')))\n",
    "\n",
    "        jul_sum = row.find_all('td')[7].text.strip()\n",
    "        july.append(int(jul_sum.replace(',','')))\n",
    "\n",
    "        aug_sum = row.find_all('td')[8].text.strip()\n",
    "        august.append(int(aug_sum.replace(',','')))\n",
    "\n",
    "        sep_sum = row.find_all('td')[9].text.strip()\n",
    "        september.append(int(sep_sum.replace(',','')))\n",
    "\n",
    "        oct_sum = row.find_all('td')[10].text.strip()\n",
    "        october.append(int(oct_sum.replace(',','')))\n",
    "\n",
    "        nov_sum = row.find_all('td')[11].text.strip()\n",
    "        november.append(int(nov_sum.replace(',','')))\n",
    "\n",
    "        dec_sum = row.find_all('td')[12].text.strip()\n",
    "        december.append(int(dec_sum.replace(',','')))\n",
    "\n",
    "    #create a dataframe containing columns corresponding to the lists generated above\n",
    "    carsaleslist.append(pd.DataFrame({'make_and_model': model_names, '{year}-01-01'.format(year = year): january,\n",
    "                              '{year}-02-01'.format(year = year): february, '{year}-03-01'.format(year = year): march,'{year}-04-01'.format(year = year): april,\n",
    "                              '{year}-05-01'.format(year = year):may, '{year}-06-01'.format(year = year):june, '{year}-07-01'.format(year = year):july,'{year}-08-01'.format(year = year):august,\n",
    "                              '{year}-09-01'.format(year = year): september, '{year}-10-01'.format(year = year): october,\n",
    "                              '{year}-11-01'.format(year = year): november,'{year}-12-01'.format(year = year): december}).replace(\"-\",\" \"))\n",
    "#compile the list of dataframes into a single dataframe, only keeping the makes and models contained in all years\n",
    "car_sales = reduce(lambda left, right:\n",
    "               pd.merge(left, right, on = 'make_and_model', how = 'outer'),\n",
    "               carsaleslist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we merge the Car Model list with the car sales dataframe to allow us to assign a body-type to each of the car models that we have sales data for"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "'''This section of the code will merge the car_sales data with the car_models data, such that every car make and model\n",
    "sold will be placed in a car body category'''\n",
    "#Read the car model csv file containing the body size category of many different car makes and models\n",
    "car_models = pd.read_csv(\"Car_Model_List.csv\")\n",
    "#read a hand-generated csv containing the models missing from the main model list but contained in the car_sales dataframe\n",
    "missing_car_models = pd.read_csv(\"missing_models.csv\")\n",
    "\n",
    "#create a list of the months considered in this analysis\n",
    "months_for_analysis = ['2019-01-01', '2019-02-01', '2019-03-01', '2019-04-01', '2019-05-01', '2019-06-01','2019-07-01',\n",
    "                       '2019-08-01', '2019-09-01', '2019-10-01', '2019-11-01', '2019-12-01',\n",
    "                       '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01', '2020-07-01',\n",
    "                       '2020-08-01', '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01',\n",
    "                       '2021-01-01', '2021-02-01', '2021-03-01', '2021-04-01', '2021-05-01', '2021-06-01', '2021-07-01',\n",
    "                       '2021-08-01', '2021-09-01', '2021-10-01', '2021-11-01', '2021-12-01']\n",
    "\n",
    "\n",
    "def make_and_model_canonicalization(car_sales, car_models,missing_car_models):\n",
    "    '''Canonicalizes car_sales such that the elements in the make_and_model column of both dataframes matches\n",
    "        input:\n",
    "        car_sales --> A dataframe containing monthly car sales for different makes and models\n",
    "        car_models --> A dataframe containing different car makes and models and their body\n",
    "\n",
    "        returns:\n",
    "        car_models dataset with modified strings in the make_and_model column to match the car_sales column canonicalization\n",
    "        car_sales dataset with modified strings in the make_and_model column to match the car_models column canonicalization\n",
    "        '''\n",
    "    car_make_list = car_models[\"Make\"].astype(str).str.lower().str.replace(\"-benz\",\"\").unique().tolist()\n",
    "    # Creating a single column for make and model, to match the format of the car_sales column\n",
    "    car_models[\"make_and_model\"] = car_models[\"Make\"].astype(str).str.lower() + \" \" + car_models[\"Model\"].astype(str).str.lower().replace(car_make_list,\" \",regex=True)\n",
    "\n",
    "    # Removing duplicates since the same make and model is present for multiple years in the car_models dataframe\n",
    "    car_models = car_models.loc[:, [\"make_and_model\", \"Category\"]].drop_duplicates().apply(lambda x: x.replace(\"-\",\" \",regex=True)\n",
    "                                                                                           .replace(\"/\",\" \",regex=True)\n",
    "                                                                                           .replace(\"benz\",\" \",regex=True)\n",
    "                                                                                           .replace(\"bolt ev\",\"bolt\",regex=True)\n",
    "                                                                                           .replace(\"passenger\",\" \",regex=True)\n",
    "                                                                                           .replace(\"crew cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"extended cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"regular cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"1500 double cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"2500 hd double cab\",\" \",regex=True)\n",
    "                                                                                           .replace(\"2500 cargo\",\" \",regex=True)\n",
    "                                                                                           .replace(\"2500 hd\",\" \",regex=True)\n",
    "                                                                                           .replace(\"3500 hd\",\" \",regex=True)\n",
    "                                                                                           .replace(\"1500\",\" \",regex=True)\n",
    "                                                                                           .replace(\"fuel cell\",\"fcv\",regex=True)\n",
    "                                                                                           .replace(\"electric\",\" \",regex=True)\n",
    "                                                                                           .replace(\"boxster\",\" \",regex=True)\n",
    "                                                                                           .replace(\"defender 90\",\"defender\",regex=True)\n",
    "                                                                                           .replace(\"slc class\",\"slc\",regex=True))\n",
    "    car_models[\"make_and_model\"] = car_models[\"make_and_model\"] \\\n",
    "        .apply(lambda x: x[:12] if (\"ford transit\" in x and \"ford transit connect\" not in x) else x)\\\n",
    "        .apply(lambda x: \"ford f series\" if \"ford f150\" in x else x)\\\n",
    "        .apply(lambda x: \"ford e series\" if \"ford e350\" in x else x)\n",
    "\n",
    "    car_sales[\"make_and_model\"] = car_sales[\"make_and_model\"].str.lower()\n",
    "    car_models[\"Category\"] = car_models[\"Category\"].replace(\"1992\",\"\",regex=True).replace(\"2020\",\"\",regex=True)\n",
    "\n",
    "    car_sales = car_sales.apply(lambda x: x.replace(\"-\", \" \",regex=True)\n",
    "                                .replace(\"/\", \" \",regex=True)\n",
    "                                .replace(\"lr4\",\" \",regex=True)\n",
    "                                .replace(\"impreza wrx\",\"wrx\",regex=True)\n",
    "                                .replace(\"fr s\",\" \",regex=True)\n",
    "                                .replace(\"benz\",\" \",regex=True)\n",
    "                                .replace(\"etron\",\"e tron\",regex=True)\n",
    "                                .replace(\"tuscon\",\"tucson\",regex=True)\n",
    "                                .replace(\"mazda3\",\"mazda 3\",regex=True)\n",
    "                                .replace(\"mazda6\",\"mazda 6\",regex=True)\n",
    "                                .replace(\"nautilus\",\" \",regex=True)\n",
    "                                .replace(\"90 series\",\"s90\",regex=True)\n",
    "                                .replace(\"60 series\",\"s60\",regex=True)\n",
    "                                .replace(\"40 series\",\"s40\",regex=True)\n",
    "                                .replace(\"pickup\",\" \",regex=True)\n",
    "                                .replace(\"family\",\" \",regex=True)\n",
    "                                .replace(\"glk class\",\" \",regex=True)\n",
    "                                .replace(\"gl gls class\",\"gls\",regex=True)\n",
    "                                .replace(\"gle class\",\"gle\",regex=True)\n",
    "                                .replace(\"slc class\",\"slc\",regex=True)\n",
    "                                .replace(\"e   cls class\",\"cls\",regex=True))\n",
    "\n",
    "    #Removing additional spaces in the strings in the male_and_model column\n",
    "    car_sales[\"make_and_model\"] = car_sales[\"make_and_model\"].apply(lambda x:' '.join(x.split()))\n",
    "    car_models[\"make_and_model\"] = car_models[\"make_and_model\"].apply(lambda x:' '.join(x.split()))\n",
    "    car_models = pd.concat([car_models, missing_car_models], axis=0)\n",
    "\n",
    "    return car_sales,car_models\n",
    "\n",
    "#Merging car_sales and car_models by make and model\n",
    "car_sales, car_models = make_and_model_canonicalization(car_sales, car_models,missing_car_models)\n",
    "car_sales_by_size = car_sales.merge(right=car_models,\n",
    "                                    how='outer',\n",
    "                                    on='make_and_model')\n",
    "\n",
    "#Filters out the vehicle makes and models that were not sold in any month from 2019-2021 in Canada\n",
    "car_sales_by_size = car_sales_by_size[~car_sales_by_size[months_for_analysis].isna().all(1) | (car_sales_by_size[months_for_analysis]==0).all(1)]\n",
    "\n",
    "#Drop duplicate rows\n",
    "car_sales_by_size = car_sales_by_size.drop_duplicates(['make_and_model'])\n",
    "\n",
    "#DEBUGGING: Finding null category values\n",
    "#car_sales_list = car_sales[\"make_and_model\"].to_list()\n",
    "#missing_cars = (car_sales_by_size[car_sales_by_size[\"Category\"].isnull()])[\"make_and_model\"].to_list()\n",
    "#print(\"Car bodies with null values: \\n\", missing_cars)\n",
    "#print(\"Number of car bodies with null values: \", len(missing_cars))\n",
    "#print(\"Car models list:\\n\", car_models[\"make_and_model\"].to_list())\n",
    "\n",
    "\n",
    "#put car model, car sales, and merged car sales list  to csv\n",
    "car_models.to_csv('Car_Model_List_updated.csv', encoding='utf-8', index=False)\n",
    "car_sales.to_csv('Car_Sales_2019_2021.csv', encoding='utf-8', index=False)\n",
    "car_sales_by_size.to_csv('Merged Car Sales List.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#print(car_sales_by_size['Category'].unique())\n",
    "\n",
    "#####################################################################################################################\n",
    "#Now combining all the data into one table\n",
    "\n",
    "#categorizing all combinations of car size category\n",
    "small_cars=[\"Coupe\",\"Hatchback\",\"Convertible\",'Convertible, Sedan','Coupe, Sedan, Convertible',\n",
    "            'Coupe, Convertible','Convertible, Sedan, Coupe','Sedan, Hatchback','Hatchback, Sedan',\n",
    "            'Hatchback, Sedan, Coupe','Convertible, Coupe, Hatchback']\n",
    "midsize_cars=[\"SUV\",\"Sedan\",\"Wagon\",'Wagon, Sedan']\n",
    "large_cars=[\"Pickup\",\"Van\",\"Minivan\",'Van Minivan']\n",
    "\n",
    "#categorizing the sizes\n",
    "car_sales_by_size['Category'] = car_sales_by_size['Category']\\\n",
    "    .apply(lambda x: 'small' if (x in small_cars) else x)\\\n",
    "    .apply(lambda x: 'midsize' if (x in midsize_cars) else x)\\\n",
    "    .apply(lambda x: 'large' if (x in large_cars) else x)\n",
    "\n",
    "#create a new dataframe with categorized % columns\n",
    "car_size_category = car_sales_by_size.groupby('Category').agg(sum)\n",
    "#print(car_size_category)\n",
    "\n",
    "#create monthly sums list\n",
    "monthly_sums = list(car_sales_by_size.sum(axis = 0)[1:-1])\n",
    "\n",
    "#calculate % proportion sales for each size of car per month\n",
    "car_size_category = (car_size_category/monthly_sums).T.rename(columns={\"small\": \"prop_small\",\n",
    "                                                                       \"midsize\": \"prop_midsize\",\n",
    "                                                                       \"large\": \"prop_large\"})\n",
    "\n",
    "##sanity check\n",
    "#car_size_category['total'] = list(car_size_category.sum(axis = 1))\n",
    "#print(car_size_category)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we add all the other features we consider to the dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "#convert to datetime index full month name and full year\n",
    "#car_size_category.index = car_size_category.reset_index()['index'].apply(lambda x: datetime.strptime(x,\"%B %Y\"))\n",
    "car_size_category.index = pd.to_datetime(car_size_category.reset_index()['index'])\n",
    "\n",
    "#create a column for monthly sums\n",
    "car_size_category['total_sum'] = monthly_sums\n",
    "\n",
    "car_size_category.to_csv('%_category.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#monthly employment stats units corrected (x1000) and datetime index set\n",
    "employment_stats = pd.read_csv(\"monthly_employment_stats_2019-2021.csv\").set_index('Labour force characteristics')\\\n",
    "    .T.astype(str).replace(',','',regex = True).astype(float)\n",
    "employment_stats.index = employment_stats.reset_index()['index'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "employment_stats[['Unemployment rate','Participation rate','Employment rate']]= employment_stats[['Unemployment rate','Participation rate','Employment rate']]/100\n",
    "employment_stats[employment_stats.columns.difference(['Unemployment rate','Participation rate','Employment rate'])]\\\n",
    "    =employment_stats[employment_stats.columns.difference(['Unemployment rate','Participation rate','Employment rate'])]*1000\n",
    "\n",
    "#employment_stats.to_csv('monthly_employment_stats_2019-2021_updated.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#monthly oil prices units corrected (cents to dollars) and datetime index set\n",
    "oil_prices = pd.read_csv(\"monthly_oil_prices_2019-2021.csv\").rename(columns={\"VALUE\": \"avg_oil_price\"})\\\n",
    "                 .set_index('REF_DATE').loc[:,'avg_oil_price'].astype(float)/100\n",
    "oil_prices.index = oil_prices.reset_index()['REF_DATE'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "#oil_prices.to_csv('monthly_oil_prices_2019-2021_updated.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#monthly transit ridership units corrected (x1 mill) and datetime index set\n",
    "transit_ridership = pd.read_csv(\"monthly_transit_ridership_2019-2021.csv\").rename(columns={\"VALUE\": \"transit_ridership\"})\\\n",
    "                        .set_index('REF_DATE').loc[:,'transit_ridership'].astype(float)*1000000\n",
    "transit_ridership.index = transit_ridership.reset_index()['REF_DATE'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "#transit_ridership.to_csv('monthly_transit_ridership_2019-2021_updated.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#monthly dollar exchange rate (USD-CAD) datetime index set\n",
    "der_usd_cad = pd.read_csv(\"monthly_der_2019-2021.csv\").rename(columns={\"FXMUSDCAD\": \"dollar_ex_rate\"})\\\n",
    "                        .set_index('date').loc[:,'dollar_ex_rate'].astype(float)\n",
    "der_usd_cad.index = der_usd_cad.reset_index()['date'].apply(lambda x: datetime.strptime(x,\"%Y-%m-%d\"))\n",
    "#print(der_usd_cad)\n",
    "\n",
    "#monthly gdp (in 2012 dollars) units correct and datetime index set\n",
    "gdp = pd.read_csv(\"monthly_oil_prices_2019-2021.csv\").rename(columns={\"VALUE\": \"gdp\"})\\\n",
    "                 .set_index('REF_DATE').loc[:,'gdp'].astype(float)*1000000\n",
    "gdp.index = gdp.reset_index()['REF_DATE'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "\n",
    "#monthly interest rates\n",
    "interest_rates = pd.read_csv('monthly_interest_rates_canada.csv')\n",
    "interest_rates['Date'] = pd.to_datetime(interest_rates['Date'])\n",
    "interest_rates.set_index('Date', drop = True, inplace= True)\n",
    "\n",
    "#merging all dataframes into using datetime indices\n",
    "total_table = pd.concat([car_size_category,employment_stats,oil_prices,transit_ridership, der_usd_cad, gdp, interest_rates], axis=1)\n",
    "total_table.to_csv('Merged Total Table.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "#Limiting table to independent variables for analysis and excluding pandemic dates from the beginning of the pandemic\n",
    "#in March 2020 until December 2020, when there was a 0% change in Canadian GDP and after which GDP stabilized.\n",
    "#https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2020009-eng.htm\n",
    "pandemic_dates = pd.to_datetime([\"2020-03-01\",\"2020-04-01\",\"2020-05-01\",\"2020-06-01\",\"2020-07-01\",\"2020-08-01\"\n",
    "                                    ,\"2020-09-01\",\"2020-10-01\",\"2020-11-01\",\"2020-12-01\",\"2021-01-01\",\"2021-02-01\",\n",
    "                                 \"2021-03-01\",\"2021-04-01\",\"2021-05-01\",\"2021-06-01\",\"2021-07-01\",\"2021-08-01\"\n",
    "                                    ,\"2021-09-01\",\"2021-10-01\",\"2021-11-01\",\"2021-12-01\"])\n",
    "\n",
    "table_for_data_analysis = total_table.drop(pandemic_dates).reset_index().loc[:,[\"index\",\"prop_large\",\"prop_midsize\"\n",
    "                                                                                   ,\"prop_small\",\"Population\"\n",
    "                                                                                   ,\"Employment rate\",\"Full-time employment\"\n",
    "                                                                                   ,\"Part-time employment\",\"Unemployment\"\n",
    "                                                                                   ,\"avg_oil_price\",\"transit_ridership\"\n",
    "                                                                                   ,\"dollar_ex_rate\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we run some analysis on the data we've included"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Scatter plot of the purchases of small, midsize, and large vehicles\n",
    "ax = sns.scatterplot(data = table_for_data_analysis, x=\"index\", y=\"prop_small\", label=\"Small cars\")\n",
    "ax = sns.scatterplot(data = table_for_data_analysis, x=\"index\", y=\"prop_midsize\", label=\"Midsize cars\")\n",
    "ax = sns.scatterplot(data = table_for_data_analysis, x=\"index\", y=\"prop_large\", label=\"Large cars\")\n",
    "plt.title('Purchases of Vehicles in Canada by Size January 2019 - December 2021', fontsize = 18)\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "#ax.xaxis.set_tick_params(labelsize = 14)\n",
    "ax.yaxis.set_tick_params(labelsize = 14)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlabel('Date', fontsize = 18)\n",
    "ax.set_ylabel('Proportion of Car Sizes Purchased', fontsize = 18)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "#Jointplots of oil prices, employment, population, and transit ridership with regards to vehicle sizes purchased\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"avg_oil_price\",\"prop_large\"]], x=\"avg_oil_price\", y=\"prop_large\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Employment rate\",\"prop_large\"]], x=\"Employment rate\", y=\"prop_large\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Full-time employment\",\"prop_large\"]], x=\"Full-time employment\", y=\"prop_large\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Part-time employment\",\"prop_large\"]], x=\"Part-time employment\", y=\"prop_large\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"transit_ridership\",\"prop_large\"]], x=\"transit_ridership\", kind=\"reg\", y=\"prop_large\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"dollar_ex_rate\",\"prop_large\"]], x=\"dollar_ex_rate\", kind=\"reg\", y=\"prop_large\")\n",
    "\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"avg_oil_price\",\"prop_midsize\"]], x=\"avg_oil_price\", y=\"prop_midsize\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Employment rate\",\"prop_midsize\"]], x=\"Employment rate\", y=\"prop_midsize\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Full-time employment\",\"prop_midsize\"]], x=\"Full-time employment\", y=\"prop_midsize\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Part-time employment\",\"prop_midsize\"]], x=\"Part-time employment\", y=\"prop_midsize\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"transit_ridership\",\"prop_midsize\"]], x=\"transit_ridership\", y=\"prop_midsize\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"dollar_ex_rate\",\"prop_midsize\"]], x=\"dollar_ex_rate\", y=\"prop_midsize\", kind=\"reg\")\n",
    "\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"avg_oil_price\",\"prop_small\"]], x=\"avg_oil_price\", y=\"prop_small\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Employment rate\",\"prop_small\"]], x=\"Employment rate\", y=\"prop_small\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Full-time employment\",\"prop_small\"]], x=\"Full-time employment\", y=\"prop_small\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"Part-time employment\",\"prop_small\"]], x=\"Part-time employment\", y=\"prop_small\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"transit_ridership\",\"prop_small\"]], x=\"transit_ridership\", y=\"prop_small\", kind=\"reg\")\n",
    "ax = sns.jointplot(data = table_for_data_analysis[[\"dollar_ex_rate\",\"prop_small\"]], x=\"dollar_ex_rate\", y=\"prop_small\", kind=\"reg\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Check for potential outliers\n",
    "print(round(table_for_data_analysis.describe(),2))\n",
    "\n",
    "#Checking for null values\n",
    "print(table_for_data_analysis.isnull().sum())\n",
    "\n",
    "#Checking correlation between variables\n",
    "correlation=table_for_data_analysis.corr()\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.title('Correlation Heatmap of Vehicle Sales in Canada Dataset')\n",
    "ax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=30)\n",
    "plt.show()\n",
    "\n",
    "#####################################################################################################################\n",
    "#Since populations and transit ridership were highly correlated, these will not be included in our model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we develop our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['prop_large', 'prop_midsize', 'prop_small', 'total_sum', 'Population',\n       'Labour force', 'Employment', 'Full-time employment',\n       'Part-time employment', 'Unemployment', 'Unemployment rate',\n       'Participation rate', 'Employment rate', 'avg_oil_price',\n       'transit_ridership', 'dollar_ex_rate', 'gdp', ' Interest Rate'],\n      dtype='object')"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 69.44444444444444%\n",
      "Test 30.555555555555557%\n",
      "Validation RMSE for small cars model: 0.02%\n",
      "Validation RMSE for midsize cars model: 0.08%\n",
      "Validation RMSE for large cars model: 0.06%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train and test splits, taking the last 30% of the data as the test data\n",
    "train = total_table.iloc[0:int(len(total_table)*0.7),:]\n",
    "test = total_table.iloc[int(len(total_table)*0.7):,:]\n",
    "\n",
    "#Verify that data was split correctly\n",
    "print('Train {}%'.format(train.shape[0] / total_table.shape[0] * 100))\n",
    "print('Test {}%'.format(test.shape[0] / total_table.shape[0] * 100))\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def process_data(data):\n",
    "    \"\"\"Process the data for the guided model, which will predict the proportion of small, midsize, and\n",
    "    large vehicles sold in Canada.\n",
    "        Input: data --> dataframe with x and y values\n",
    "        Output: X --> explanatory variables\n",
    "                y1 --> proportion of small vehicles purchased\n",
    "                y2 --> proportion of midsize vehicles purchased\n",
    "                y3 --> proportion of large vehicles purchased\n",
    "    \"\"\"\n",
    "    # Transform Data, Select Features\n",
    "    data = select_columns(data,\n",
    "                          'avg_oil_price',\n",
    "                          'Full-time employment',\n",
    "                          'Part-time employment',\n",
    "                          'dollar_ex_rate',\n",
    "                          'Employment rate',\n",
    "                          'transit_ridership',\n",
    "                          'interest_rate',\n",
    "                          'prop_small',\n",
    "                          'prop_midsize',\n",
    "                          'prop_large')\n",
    "\n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['prop_small','prop_midsize','prop_large'], axis=1)\n",
    "    y_small = data.loc[:, 'prop_small']\n",
    "    y_midsize = data.loc[:, 'prop_midsize']\n",
    "    y_large = data.loc[:, 'prop_large']\n",
    "\n",
    "    return X, y_small, y_midsize, y_large\n",
    "\n",
    "#Separating data into training, validation, and test datasets\n",
    "X_train, y_train_small, y_train_midsize, y_train_large = process_data(train)\n",
    "X_test, y_test_small, y_test_midsize, y_test_large = process_data(test)\n",
    "\n",
    "#Scaling variables based on minimum and maximum values to be within 0 and 1\n",
    "cols = X_train.columns\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns = cols)\n",
    "X_test = pd.DataFrame(X_test, columns = cols)\n",
    "\n",
    "#Training linear regression models for small, midsize, and large vehicle sales\n",
    "linear_model_small = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_midsize = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_large = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "#cross validation\n",
    "results = []\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, val_index in tscv.split(X_train):\n",
    "    X_training, X_val = X_train.iloc[train_index,:], X_train.iloc[val_index,:]\n",
    "    y_training_small, y_training_midsize, y_training_large = y_train_small.iloc[train_index], y_train_midsize.iloc[train_index], y_train_large.iloc[train_index]\n",
    "    y_val_small, y_val_midsize, y_val_large = y_train_small.iloc[val_index], y_train_midsize.iloc[val_index], y_train_large.iloc[val_index]\n",
    "\n",
    "    #fit the models for each fold\n",
    "    linear_model_small.fit(X_training, y_training_small)\n",
    "    linear_model_midsize.fit(X_training, y_training_midsize)\n",
    "    linear_model_large.fit(X_training, y_training_large)\n",
    "\n",
    "    y_predicted_small = linear_model_small.predict(X_val)\n",
    "    y_predicted_midsize = linear_model_midsize.predict(X_val)\n",
    "    y_predicted_large = linear_model_large.predict(X_val)\n",
    "\n",
    "    results.append([mean_squared_error(y_val_small, y_predicted_small), mean_squared_error(y_val_midsize, y_predicted_midsize), mean_squared_error(y_val_large, y_predicted_large)])\n",
    "errors = pd.DataFrame(results, columns = ['small', 'midsize', 'large'])\n",
    "# Printing calculated error values for the validation sets of the three models\n",
    "print('Validation RMSE for small cars model: {:.2f}%'.format(errors.min()[0]*100))\n",
    "print('Validation RMSE for midsize cars model: {:.2f}%'.format(errors.min()[1]*100))\n",
    "print('Validation RMSE for large cars model: {:.2f}%'.format(errors.min()[2]*100))\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "      small   midsize     large\n0  0.000235  0.004170  0.004385\n1  0.000322  0.000787  0.000573\n2  0.000352  0.340638  0.321445\n3  0.001887  0.006905  0.015847\n4  0.000818  0.004329  0.004183",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>small</th>\n      <th>midsize</th>\n      <th>large</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000235</td>\n      <td>0.004170</td>\n      <td>0.004385</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000322</td>\n      <td>0.000787</td>\n      <td>0.000573</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000352</td>\n      <td>0.340638</td>\n      <td>0.321445</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001887</td>\n      <td>0.006905</td>\n      <td>0.015847</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000818</td>\n      <td>0.004329</td>\n      <td>0.004183</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "def cross_validate_rmse(model, X, y):\n",
    "    # Setup\n",
    "    model = clone(model)\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "    rmse_values = []\n",
    "\n",
    "    # Iterature thought cv-folds\n",
    "    for train_index, val_index in loo.split(X):\n",
    "        X_train, y_train = np.array(X)[train_index], np.array(y)[train_index]\n",
    "        X_test, y_test = np.array(X)[val_index], np.array(y)[val_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predicted = model.predict(X_test)\n",
    "\n",
    "        # Append RMSE scores\n",
    "        rmse_values.append(rmse(y_test, predicted))\n",
    "    return rmse_values\n",
    "\n",
    "cv_scores_small = cross_validate_rmse(model=lm.LinearRegression(fit_intercept=True), X=X_train, y=y_train_small)\n",
    "cv_scores_midsize = cross_validate_rmse(model=lm.LinearRegression(fit_intercept=True), X=X_train, y=y_train_midsize)\n",
    "cv_scores_large = cross_validate_rmse(model=lm.LinearRegression(fit_intercept=True), X=X_train, y=y_train_large)\n",
    "\n",
    "# Print cv scores\n",
    "print('Cross-validation RMSE scores for small cars model: {}'.format(cv_scores_small))\n",
    "print('Cross-validation RMSE scores mean for small cars model: {} cars'.format(np.mean(cv_scores_small)))\n",
    "print('Cross-validation RMSE scores std for small cars model: {} cars'.format(np.std(cv_scores_small)))\n",
    "print('\\n')\n",
    "print('Cross-validation RMSE scores for midsize cars model: {}'.format(cv_scores_midsize))\n",
    "print('Cross-validation RMSE scores mean for midsize cars model: {} cars'.format(np.mean(cv_scores_midsize)))\n",
    "print('Cross-validation RMSE scores std for midsize cars model: {} cars'.format(np.std(cv_scores_midsize)))\n",
    "print('\\n')\n",
    "print('Cross-validation RMSE scores for large cars model: {}'.format(cv_scores_large))\n",
    "print('Cross-validation RMSE scores mean for large cars model: {} cars'.format(np.mean(cv_scores_large)))\n",
    "print('Cross-validation RMSE scores std for large cars model: {} cars'.format(np.std(cv_scores_large)))\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
